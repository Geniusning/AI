{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374278d7",
   "metadata": {},
   "source": [
    "## GPT4v实战：API调用、使用场景实践"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b1b37",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>注意：</b>\n",
    "<p>由于网络原因下面代码务必在自己的电脑上运行，才能看到界面</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240c2a2",
   "metadata": {},
   "source": [
    "## 步骤 1：安装所需依赖的包\n",
    "\n",
    "确保你已经安装了 Python，并使用 pip 安装 Gradio, OpenAI, 以及Gemini所需依赖库：\n",
    "\n",
    "#### 如果在本地电脑执行下面命令\n",
    "\n",
    "```\n",
    "pip  install gradio openai google-generativeai\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c12c38",
   "metadata": {},
   "source": [
    "## 如果在实验室执行下面命令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4145874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio==3.50\n",
      "  Using cached gradio-3.50.0-py3-none-any.whl (20.3 MB)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (23.2.1)\n",
      "Collecting altair<6.0,>=4.2.0 (from gradio==3.50)\n",
      "  Using cached altair-5.2.0-py3-none-any.whl (996 kB)\n",
      "Collecting fastapi (from gradio==3.50)\n",
      "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ffmpy (from gradio==3.50)\n",
      "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gradio-client==0.6.1 (from gradio==3.50)\n",
      "  Using cached gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
      "Requirement already satisfied: httpx in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (0.26.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (0.20.1)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (6.0.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (2.1.3)\n",
      "Collecting matplotlib~=3.0 (from gradio==3.50)\n",
      "  Downloading matplotlib-3.8.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m121.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy~=1.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (1.26.2)\n",
      "Collecting orjson~=3.0 (from gradio==3.50)\n",
      "  Downloading orjson-3.9.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (23.2)\n",
      "Collecting pandas<3.0,>=1.0 (from gradio==3.50)\n",
      "  Downloading pandas-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (10.1.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (2.5.3)\n",
      "Collecting pydub (from gradio==3.50)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting python-multipart (from gradio==3.50)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (6.0)\n",
      "Requirement already satisfied: requests~=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (2.31.0)\n",
      "Collecting semantic-version~=2.0 (from gradio==3.50)\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (4.7.1)\n",
      "Collecting uvicorn>=0.14.0 (from gradio==3.50)\n",
      "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio==3.50)\n",
      "  Using cached websockets-11.0.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from gradio-client==0.6.1->gradio==3.50) (2023.12.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio==3.50) (4.20.0)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio==3.50) (0.12.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.14.0->gradio==3.50) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.14.0->gradio==3.50) (4.65.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio==3.50)\n",
      "  Using cached contourpy-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (313 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib~=3.0->gradio==3.50)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio==3.50)\n",
      "  Downloading fonttools-4.49.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib~=3.0->gradio==3.50)\n",
      "  Using cached kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib~=3.0->gradio==3.50)\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio==3.50) (2023.3)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0,>=1.0->gradio==3.50)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50) (2.14.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests~=2.0->gradio==3.50) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests~=2.0->gradio==3.50) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests~=2.0->gradio==3.50) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests~=2.0->gradio==3.50) (2023.11.17)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from uvicorn>=0.14.0->gradio==3.50) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.11/site-packages (from uvicorn>=0.14.0->gradio==3.50) (0.14.0)\n",
      "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio==3.50)\n",
      "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions~=4.0 (from gradio==3.50)\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.11/site-packages (from httpx->gradio==3.50) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx->gradio==3.50) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from httpx->gradio==3.50) (1.3.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50) (2023.6.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50) (0.29.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50) (0.8.10)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.50) (1.16.0)\n",
      "Building wheels for collected packages: ffmpy\n",
      "  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=3a9a719bc60700f5178f1b582dda1b204e22c228eaef308883cc0cd1d0283ab4\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/55/3c/f2/f6e34046bac0d57c13c7d08123b85872423b89c8f59bafda51\n",
      "Successfully built ffmpy\n",
      "Installing collected packages: pydub, ffmpy, websockets, uvicorn, tzdata, typing-extensions, semantic-version, python-multipart, pyparsing, orjson, kiwisolver, fonttools, cycler, contourpy, starlette, pandas, matplotlib, gradio-client, fastapi, altair, gradio\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "doctran 0.0.14 requires openai<0.28.0,>=0.27.8, but you have openai 1.6.1 which is incompatible.\n",
      "doctran 0.0.14 requires pydantic<2.0.0,>=1.10.9, but you have pydantic 2.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed altair-5.2.0 contourpy-1.2.0 cycler-0.12.1 fastapi-0.110.0 ffmpy-0.3.2 fonttools-4.49.0 gradio-3.50.0 gradio-client-0.6.1 kiwisolver-1.4.5 matplotlib-3.8.3 orjson-3.9.15 pandas-2.2.1 pydub-0.25.1 pyparsing-3.1.1 python-multipart-0.0.9 semantic-version-2.10.0 starlette-0.36.3 typing-extensions-4.10.0 tzdata-2024.1 uvicorn-0.27.1 websockets-11.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gradio==3.50  # 在实验室运行时执行的代码，本地不需要\n",
    "%pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559039ff",
   "metadata": {},
   "source": [
    "下面代码创建了一个 Gradio 用户界面，可以在文本框中输入问题，并上传最多三张图像。\n",
    "这些输入将传递给 query_gpt4_vision 函数，该函数使用 OpenAI GPT-4 Vision 模型生成对问题的回答。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45cbb7",
   "metadata": {},
   "source": [
    "## 步骤 2：编写 Gradio 与 GPT-4 Vision 应用\n",
    "在你的 Python 脚本中，编写 Gradio 应用。以下是一个例子，使用 GPT-4 Vision 模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f61f40-d846-46a7-b7ab-d31b2fd2f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "googleapi_key = os.getenv('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55b5749e-2180-4575-921a-480e0f1b029f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "Running on public URL: https://19c26f3cbf48f8cad2.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://19c26f3cbf48f8cad2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io, os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Function to encode the image to base64\n",
    "def encode_image_to_base64(image):\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "# Function to query GPT-4 Vision\n",
    "def query_gpt4_vision(text, image1, image2, image3):\n",
    "    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": text}]}]\n",
    "\n",
    "    images = [image1, image2, image3]\n",
    "    for image in images:\n",
    "        if image is not None:\n",
    "            base64_image = encode_image_to_base64(image)\n",
    "            image_message = {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "            }\n",
    "            messages[0][\"content\"].append(image_message)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-vision-preview\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Function to query Gemini-Pro\n",
    "def query_gemini_vision(text, image1, image2, image3):\n",
    "    # Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "    #GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
    "    GOOGLE_API_KEY=os.getenv('GOOGLE_API_KEY')\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    model = genai.GenerativeModel('gemini-pro-vision')\n",
    "\n",
    "    images = [image1, image2, image3]\n",
    "    query = [text]\n",
    "    for image in images:\n",
    "        if image is not None:\n",
    "            query.append(image)\n",
    "    response = model.generate_content(query, stream=False)\n",
    "    response.resolve()\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "# 由于Gradio 2.0及以上版本的界面构建方式有所不同，这里使用blocks API来创建更复杂的UI\n",
    "def main():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"### 输入文本\")\n",
    "        input_text = gr.Textbox(lines=2, label=\"输入文本\")\n",
    "        input_images = [gr.Image(type=\"pil\", label=\"Upload Image\", tool=\"editor\") for i in range(3)]\n",
    "        output_gpt4 = gr.Textbox(label=\"GPT-4 输出\")\n",
    "        output_other_api = gr.Textbox(label=\"Gemini-Pro 输出\")\n",
    "        btn_gpt4 = gr.Button(\"调用GPT-4\")\n",
    "        btn_other_api = gr.Button(\"调用Gemini-Pro\")\n",
    "\n",
    "        btn_gpt4.click(fn=query_gpt4_vision, inputs=[input_text] + input_images, outputs=output_gpt4)\n",
    "        btn_other_api.click(fn=query_gemini_vision, inputs=[input_text] + input_images, outputs=output_other_api)\n",
    "\n",
    "    demo.launch(share=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba8a19c",
   "metadata": {},
   "source": [
    "## 步骤 3：运行 Gradio 应用\n",
    "保存并运行你的 Python 脚本。这将启动 Gradio 用户界面，并在终端中显示本地运行的 URL（通常是 http://127.0.0.1:7860）。访问该 URL 即可查看和使用你的 Gradio 应用。\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>建议：</b>\n",
    "<li>确保你的机器上已经安装了必要的 Python 包。</li>\n",
    "<li> 如果使用 OpenAI 模型，确保你已经设置了正确的 API 密钥。 </li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d35267",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8063afad-6b39-4a67-8885-57931e7236a8",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "- 菜品价格预估：估算一下这桌子菜的价格，给出每道菜的市场价格。假设这是北京的一家中档餐厅\n",
    "- figure理解：请生成这张图片的caption\n",
    "- 网页设计：生成下面设计图对应的网站源码\n",
    "- 视觉结合知识的推断：根据图中信息，猜测这是什么型号的GPU？请列出所有可能的GPU型号，并给出你的判断依据。猜测大致的生产年限"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5daeb844-eb3d-409b-8be6-f23de1267e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "Running on public URL: https://c4be06db92e0263fab.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c4be06db92e0263fab.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io, os\n",
    "\n",
    "# Function to encode the image to base64\n",
    "def encode_image_to_base64(image):\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "# Function to query GPT-4 Vision\n",
    "def query_gpt4_vision(*inputs):\n",
    "    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    messages = [{\"role\": \"user\", \"content\": []}]\n",
    "\n",
    "    for input_item in inputs:\n",
    "        if isinstance(input_item, str):  # Text input\n",
    "            messages[0][\"content\"].append({\"type\": \"text\", \"text\": input_item})\n",
    "        elif isinstance(input_item, Image.Image):  # Image input\n",
    "            base64_image = encode_image_to_base64(input_item)\n",
    "            messages[0][\"content\"].append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "            })\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-vision-preview\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Function to query Gemini-Pro\n",
    "def query_gemini_vision(*inputs):\n",
    "    # Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "    #GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
    "    GOOGLE_API_KEY=os.getenv('GOOGLE_API_KEY')\n",
    "    #print(GOOGLE_API_KEY)\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    model = genai.GenerativeModel('gemini-pro-vision')\n",
    "\n",
    "    query = []\n",
    "    for item in inputs:\n",
    "        if item is not None:\n",
    "            query.append(item)\n",
    "    response = model.generate_content(query, stream=False)\n",
    "    response.resolve()\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "'''\n",
    "    \n",
    "# Dynamically generate input components\n",
    "input_components = []\n",
    "for i in range(2):  # Change this number to add more inputs\n",
    "    input_components.append(gr.components.Textbox(lines=2, placeholder=f\"Enter your text input {i+1}...\"))\n",
    "    input_components.append(gr.components.Image(type=\"pil\", label=f\"Upload Image {i+1}\", tool=\"editor\"))\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=query_gpt4_vision,\n",
    "    inputs=input_components,\n",
    "    outputs=gr.components.Text(update=True), \n",
    ")\n",
    "\n",
    "iface.launch(share=True)\n",
    "\n",
    "'''\n",
    "    \n",
    "# 由于Gradio 2.0及以上版本的界面构建方式有所不同，这里使用blocks API来创建更复杂的UI\n",
    "def main():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"### 输入文本\")\n",
    "        #input_text = gr.Textbox(lines=2, label=\"输入文本\")\n",
    "        input_components = []\n",
    "        for i in range(2):  # Change this number to add more inputs\n",
    "            input_components.append(gr.Textbox(lines=2, placeholder=f\"Enter your text input {i+1}...\"))\n",
    "            input_components.append(gr.Image(type=\"pil\", label=f\"Upload Image {i+1}\", tool=\"editor\"))\n",
    "    \n",
    "        #input_images = [gr.Image(type=\"pil\", label=\"Upload Image\", tool=\"editor\") for i in range(3)]\n",
    "        output_gpt4 = gr.Textbox(label=\"GPT-4 输出\")\n",
    "        output_other_api = gr.Textbox(label=\"Gemini-Pro 输出\")\n",
    "        btn_gpt4 = gr.Button(\"调用GPT-4\")\n",
    "        btn_other_api = gr.Button(\"调用Gemini-Pro\")\n",
    "\n",
    "        btn_gpt4.click(fn=query_gpt4_vision, inputs=input_components, outputs=output_gpt4)\n",
    "        btn_other_api.click(fn=query_gemini_vision, inputs=input_components, outputs=output_other_api)\n",
    "\n",
    "    demo.launch(share=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc09939-2aaa-456a-ada6-ac8c69b33cdd",
   "metadata": {},
   "source": [
    "- 具身智能场景：\n",
    "  假设你是一个机器人，在厨房从事工作，你会执行的操作包括  靠近(物体坐标)， 抓取(物体坐标),  移动(开始坐标，结束坐标)，这里的坐标需要根据你的视觉系统来估计xy位置，以及深度信息z。人类会给你指令，你需要按照人类指令要求的完成对应的操作。比如，人类：把抽屉里的绿色包装袋拿出来。此时你看到的画面是这样的：\n",
    "  请问接下来你该执行什么指令？只给出指令即可，但是需要包括具体的坐标信息（假设当前画面的长宽为单位1，使用你估计的深度信息以及xy偏移位置）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00320ab-8cb2-4dae-8646-31fb095d9ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95875cc-1969-4e8b-9dfd-74629010da00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
